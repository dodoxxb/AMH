{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51271521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import collections\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "plt.style.use('bmh')\n",
    "\n",
    "try:\n",
    "    from IPython.display import clear_output\n",
    "    have_ipython = True\n",
    "except ImportError:\n",
    "    have_ipython = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(y, y_hat):\n",
    "    return sum(yi == yi_hat for yi, yi_hat in zip(y, y_hat)) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnnDtw(object):\n",
    "    \"\"\"K-nearest neighbor classifier using dynamic time warping\n",
    "    as the distance measure between pairs of time series arrays\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    n_neighbors : int, optional (default = 5)\n",
    "        Number of neighbors to use by default for KNN\n",
    "\n",
    "    max_warping_window : int, optional (default = infinity)\n",
    "        Maximum warping window allowed by the DTW dynamic\n",
    "        programming function\n",
    "\n",
    "    subsample_step : int, optional (default = 1)\n",
    "        Step size for the timeseries array. By setting subsample_step = 2,\n",
    "        the timeseries length will be reduced by 50% because every second\n",
    "        item is skipped. Implemented by x[:, ::subsample_step]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=5, max_warping_window=10000, subsample_step=1):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.max_warping_window = max_warping_window\n",
    "        self.subsample_step = subsample_step\n",
    "\n",
    "    def fit(self, x, l):\n",
    "        \"\"\"Fit the model using x as training data and l as class labels\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : array of shape [n_samples, n_timepoints]\n",
    "            Training data set for input into KNN classifer\n",
    "\n",
    "        l : array of shape [n_samples]\n",
    "            Training labels for input into KNN classifier\n",
    "        \"\"\"\n",
    "\n",
    "        self.x = x\n",
    "        self.l = l\n",
    "\n",
    "    def _dtw_distance(self, ts_a, ts_b, d = lambda x,y: abs(x-y)):\n",
    "        \"\"\"Returns the DTW similarity distance between two 2-D\n",
    "        timeseries numpy arrays.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        ts_a, ts_b : array of shape [n_samples, n_timepoints]\n",
    "            Two arrays containing n_samples of timeseries data\n",
    "            whose DTW distance between each sample of A and B\n",
    "            will be compared\n",
    "\n",
    "        d : DistanceMetric object (default = abs(x-y))\n",
    "            the distance measure used for A_i - B_j in the\n",
    "            DTW dynamic programming function\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DTW distance between A and B\n",
    "        \"\"\"\n",
    "\n",
    "        # Create cost matrix via broadcasting with large int\n",
    "        ts_a, ts_b = np.array(ts_a), np.array(ts_b)\n",
    "        M, N = len(ts_a), len(ts_b)\n",
    "        cost = sys.maxsize * np.ones((M, N))\n",
    "\n",
    "        # Initialize the first row and column\n",
    "        cost[0, 0] = d(ts_a[0], ts_b[0])\n",
    "        for i in range(1, M):\n",
    "            cost[i, 0] = cost[i-1, 0] + d(ts_a[i], ts_b[0])\n",
    "\n",
    "        for j in range(1, N):\n",
    "            cost[0, j] = cost[0, j-1] + d(ts_a[0], ts_b[j])\n",
    "\n",
    "        # Populate rest of cost matrix within window\n",
    "        for i in range(1, M):\n",
    "            for j in range(max(1, i - self.max_warping_window),\n",
    "                           min(N, i + self.max_warping_window)):\n",
    "                choices = cost[i - 1, j - 1], cost[i, j-1], cost[i-1, j]\n",
    "                cost[i, j] = min(choices) + d(ts_a[i], ts_b[j])\n",
    "\n",
    "        # Return DTW distance given window\n",
    "        return cost[-1, -1]\n",
    "\n",
    "    def _dist_matrix(self, x, y):\n",
    "        \"\"\"Computes the M x N distance matrix between the training\n",
    "        dataset and testing dataset (y) using the DTW distance measure\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : array of shape [n_samples, n_timepoints]\n",
    "\n",
    "        y : array of shape [n_samples, n_timepoints]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Distance matrix between each item of x and y with\n",
    "            shape [training_n_samples, testing_n_samples]\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute the distance matrix\n",
    "        dm_count = 0\n",
    "\n",
    "        # Compute condensed distance matrix (upper triangle) of pairwise dtw distances\n",
    "        # when x and y are the same array\n",
    "        if(np.array_equal(x, y)):\n",
    "            x_s = np.shape(x)\n",
    "            dm = np.zeros((x_s[0] * (x_s[0] - 1)) // 2, dtype=np.double)\n",
    "\n",
    "            p = ProgressBar(dm.shape[0])\n",
    "\n",
    "            for i in range(0, x_s[0] - 1):\n",
    "                for j in range(i + 1, x_s[0]):\n",
    "                    dm[dm_count] = self._dtw_distance(x[i, ::self.subsample_step],\n",
    "                                                      y[j, ::self.subsample_step])\n",
    "\n",
    "                    dm_count += 1\n",
    "                    p.animate(dm_count)\n",
    "\n",
    "            # Convert to squareform\n",
    "            dm = squareform(dm)\n",
    "            return dm\n",
    "\n",
    "        # Compute full distance matrix of dtw distnces between x and y\n",
    "        else:\n",
    "            x_s = np.shape(x)\n",
    "            y_s = np.shape(y)\n",
    "            dm = np.zeros((x_s[0], y_s[0]))\n",
    "            dm_size = x_s[0]*y_s[0]\n",
    "\n",
    "            p = ProgressBar(dm_size)\n",
    "\n",
    "            for i in range(0, x_s[0]):\n",
    "                for j in range(0, y_s[0]):\n",
    "                    dm[i, j] = self._dtw_distance(x[i, ::self.subsample_step],\n",
    "                                                  y[j, ::self.subsample_step])\n",
    "                    # Update progress bar\n",
    "                    dm_count += 1\n",
    "                    p.animate(dm_count)\n",
    "\n",
    "            return dm\n",
    "\n",
    "    def predict(self, x, y):\n",
    "        \"\"\"Predict the class labels or probability estimates for\n",
    "        the provided data\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "          x : array of shape [n_samples, n_timepoints]\n",
    "              Array containing the testing data set to be classified\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          2 arrays representing:\n",
    "              (1) the predicted class labels\n",
    "              (2) the knn label count probability\n",
    "        \"\"\"\n",
    "\n",
    "        dm = self._dist_matrix(x, self.x)\n",
    "\n",
    "        acc = []\n",
    "\n",
    "        # Identify the k nearest neighbors\n",
    "        # argsort() 从小到大排列，返回index大小的顺序\n",
    "        for i in range(2, 209):\n",
    "            knn_idx = dm.argsort()[:, :i]\n",
    "\n",
    "            # Identify k nearest labels\n",
    "            knn_labels = self.l[knn_idx]\n",
    "\n",
    "            # Model Label\n",
    "            mode_data = mode(knn_labels, axis=1)\n",
    "            mode_label = mode_data[0]\n",
    "            mode_proba = mode_data[1]/i\n",
    "            acc.append(cal_acc(y, mode_label))\n",
    "\n",
    "        best = acc.index(max(acc))\n",
    "        # print('best k value:', best)\n",
    "        # print('\\n Acc:', acc[best])\n",
    "\n",
    "        knn_idx = dm.argsort()[:, :best]\n",
    "\n",
    "        # Identify k nearest labels\n",
    "        knn_labels = self.l[knn_idx]\n",
    "\n",
    "        # Model Label\n",
    "        mode_data = mode(knn_labels, axis=1)\n",
    "        mode_label = mode_data[0]\n",
    "        mode_proba = mode_data[1]/best\n",
    "\n",
    "        return mode_label.ravel(), mode_proba.ravel(), best, max(acc)\n",
    "\n",
    "    def test_predict(self, x):\n",
    "\n",
    "        dm = self._dist_matrix(x, self.x)\n",
    "\n",
    "        knn_idx = dm.argsort()[:, :self.n_neighbors]\n",
    "\n",
    "        # Identify k nearest labels\n",
    "        knn_labels = self.l[knn_idx]\n",
    "\n",
    "        # Model Label\n",
    "        mode_data = mode(knn_labels, axis=1)\n",
    "        mode_label = mode_data[0]\n",
    "        mode_proba = mode_data[1]/self.n_neighbors\n",
    "\n",
    "        return mode_label.ravel(), mode_proba.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54295f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressBar:\n",
    "    \"\"\"This progress bar was taken from PYMC\n",
    "    \"\"\"\n",
    "    def __init__(self, iterations):\n",
    "        self.iterations = iterations\n",
    "        self.prog_bar = '[]'\n",
    "        self.fill_char = '*'\n",
    "        self.width = 40\n",
    "        self.__update_amount(0)\n",
    "        if have_ipython:\n",
    "            self.animate = self.animate_ipython\n",
    "        else:\n",
    "            self.animate = self.animate_noipython\n",
    "\n",
    "    def animate_ipython(self, iter):\n",
    "        print ('\\r', self,)\n",
    "        sys.stdout.flush()\n",
    "        self.update_iteration(iter + 1)\n",
    "\n",
    "    def update_iteration(self, elapsed_iter):\n",
    "        self.__update_amount((elapsed_iter / float(self.iterations)) * 100.0)\n",
    "        self.prog_bar += '  %d of %s complete' % (elapsed_iter, self.iterations)\n",
    "\n",
    "    def __update_amount(self, new_amount):\n",
    "        percent_done = int(round((new_amount / 100.0) * 100.0))\n",
    "        all_full = self.width - 2\n",
    "        num_hashes = int(round((percent_done / 100.0) * all_full))\n",
    "        self.prog_bar = '[' + self.fill_char * num_hashes + ' ' * (all_full - num_hashes) + ']'\n",
    "        pct_place = (len(self.prog_bar) // 2) - len(str(percent_done))\n",
    "        pct_string = '%d%%' % percent_done\n",
    "        self.prog_bar = self.prog_bar[0:pct_place] + \\\n",
    "                        (pct_string + self.prog_bar[pct_place + len(pct_string):])\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.prog_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path):\n",
    "\n",
    "    br = []\n",
    "    deltaBp = []\n",
    "    hr = []\n",
    "    hrSnr = []\n",
    "    hrv = []\n",
    "    relax = []\n",
    "    stress = []\n",
    "    stressSnr = []\n",
    "\n",
    "    df_br = pd.read_csv(csv_path, encoding=\"gbk\",\n",
    "                        usecols=[\"br\", \"deltaBp\", \"hr\", \"hrSnr\", \"hrv\", \"relax\", \"stress\", \"stressSnr\"])\n",
    "    # print(df_br)\n",
    "\n",
    "    for index, row in df_br.iterrows():\n",
    "        br.append(row['br'])\n",
    "        deltaBp.append(row['deltaBp'])\n",
    "        hr.append(row['hr'])\n",
    "        hrSnr.append(row['hrSnr'])\n",
    "        hrv.append(row['hrv'])\n",
    "        relax.append(row['relax'])\n",
    "        stress.append(row['stress'])\n",
    "        stressSnr.append(row['stressSnr'])\n",
    "\n",
    "    avg_br = np.mean(br)\n",
    "    avg_deltaBp = np.mean(deltaBp)\n",
    "    avg_hr = np.mean(hr)\n",
    "    avg_hrSnr = np.mean(hrSnr)\n",
    "    avg_hrv = np.mean(hrv)\n",
    "    avg_relax = np.mean(relax)\n",
    "    avg_stress = np.mean(stress)\n",
    "    avg_stressSnr = np.mean(stressSnr)\n",
    "\n",
    "    # print(index)\n",
    "    for i in range(699-index):\n",
    "        br.append(avg_br)\n",
    "        deltaBp.append(avg_deltaBp)\n",
    "        hr.append(avg_hr)\n",
    "        hrSnr.append(avg_hrSnr)\n",
    "        hrv.append(avg_hrv)\n",
    "        relax.append(avg_relax)\n",
    "        stress.append(avg_stress)\n",
    "        stressSnr.append(avg_stressSnr)\n",
    "\n",
    "    return br, deltaBp, hr, hrSnr, hrv, relax, stress, stressSnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    X_br = []\n",
    "    X_deltaBp = []\n",
    "    X_hr = []\n",
    "    X_hrSnr = []\n",
    "    X_hrv = []\n",
    "    X_relax = []\n",
    "    X_stress = []\n",
    "    X_stressSnr = []\n",
    "    \n",
    "    nn_input = []\n",
    "    \n",
    "    y = []\n",
    "\n",
    "    num = 0    \n",
    "    \n",
    "    dataset_path = './dataset'\n",
    "    json_suffix = '.json'\n",
    "    csv_suffix = '.csv'\n",
    "    dataset_class = os.listdir(dataset_path)\n",
    "\n",
    "    labels = {0:'unhealthy', 1:'healthy'}\n",
    "\n",
    "    for sample_class in dataset_class:\n",
    "        sample_class_path = dataset_path + '/' + sample_class\n",
    "        sample_file = os.listdir(sample_class_path)\n",
    "\n",
    "        for detail in sample_file:\n",
    "            detail_path = sample_class_path + '/' + detail\n",
    "            # print(detail_path)\n",
    "            sample_detail = os.listdir(detail_path)\n",
    "            json_path = detail_path + '/' + detail + '_emotion.json'\n",
    "            # print(json_path)\n",
    "            csv_path = json_path.replace(json_suffix, '') + csv_suffix\n",
    "            # print(csv_path)\n",
    "\n",
    "            if sample_class == 'healthy' and num >= 90:\n",
    "                # print('healthy')\n",
    "                # load_data(csv_path)\n",
    "                br, deltaBp, hr, hrSnr, hrv, relax, stress, stressSnr = load_data(csv_path)\n",
    "\n",
    "                X_br.append(br)\n",
    "                X_deltaBp.append(deltaBp)\n",
    "                X_hr.append(hr)\n",
    "                X_hrSnr.append(hrSnr)\n",
    "                X_hrv.append(hrv)\n",
    "                X_relax.append(relax)\n",
    "                X_stress.append(stress)\n",
    "                X_stressSnr.append(stressSnr)\n",
    "\n",
    "                y.append(1)\n",
    "                \n",
    "                num += 1\n",
    "                \n",
    "\n",
    "            elif sample_class == 'unhealthy':\n",
    "                br, deltaBp, hr, hrSnr, hrv, relax, stress, stressSnr = load_data(csv_path)\n",
    "                # temp = np.array(temp)\n",
    "                # X.append(temp)\n",
    "\n",
    "                X_br.append(br)\n",
    "                X_deltaBp.append(deltaBp)\n",
    "                X_hr.append(hr)\n",
    "                X_hrSnr.append(hrSnr)\n",
    "                X_hrv.append(hrv)\n",
    "                X_relax.append(relax)\n",
    "                X_stress.append(stress)\n",
    "                X_stressSnr.append(stressSnr)\n",
    "\n",
    "                y.append(0)\n",
    "\n",
    "            else :\n",
    "                print('Another data file exist')\n",
    "                continue\n",
    "\n",
    "    X_br = np.array(X_br)\n",
    "    X_deltaBp = np.array(X_deltaBp)\n",
    "    X_hr = np.array(X_hr)\n",
    "    X_hrSnr = np.array(X_hrSnr)\n",
    "    X_hrv = np.array(X_hrv)\n",
    "    X_relax = np.array(X_relax)\n",
    "    X_stress = np.array(X_stress)\n",
    "    X_stressSnr = np.array(X_stressSnr)\n",
    "\n",
    "    y = np.array(y)\n",
    "    \n",
    "    \n",
    "\n",
    "    X_br_train, X_br_test, y_br_train, y_br_test = train_test_split(X_br, y,\n",
    "                                                                    test_size=0.5, random_state=42)\n",
    "    X_br_train = np.array(X_br_train)\n",
    "    y_br_train = np.array(y_br_train)\n",
    "    X_br_test = np.array(X_br_test)\n",
    "    y_br_test = np.array(y_br_test)\n",
    "\n",
    "    X_deltaBp_train, X_deltaBp_test, y_deltaBp_train, y_deltaBp_test = train_test_split(X_deltaBp, y,\n",
    "                                                                                        test_size=0.5, random_state=42)\n",
    "    X_deltaBp_train = np.array(X_deltaBp_train)\n",
    "    y_deltaBp_train = np.array(y_deltaBp_train)\n",
    "    X_deltaBp_test = np.array(X_deltaBp_test)\n",
    "    y_deltaBp_test = np.array(y_deltaBp_test)\n",
    "\n",
    "    X_hr_train, X_hr_test, y_hr_train, y_hr_test = train_test_split(X_hr, y, test_size=0.5, random_state=42)\n",
    "    X_hr_train = np.array(X_hr_train)\n",
    "    y_hr_train = np.array(y_hr_train)\n",
    "    X_hr_test = np.array(X_hr_test)\n",
    "    y_hr_test = np.array(y_hr_test)\n",
    "\n",
    "    X_hrSnr_train, X_hrSnr_test, y_hrSnr_train, y_hrSnr_test = train_test_split(X_hrSnr, y,\n",
    "                                                                                test_size=0.5, random_state=42)\n",
    "    X_hrSnr_train = np.array(X_hrSnr_train)\n",
    "    y_hrSnr_train = np.array(y_hrSnr_train)\n",
    "    X_hrSnr_test = np.array(X_hrSnr_test)\n",
    "    y_hrSnr_test = np.array(y_hrSnr_test)\n",
    "\n",
    "    X_hrv_train, X_hrv_test, y_hrv_train, y_hrv_test = train_test_split(X_hrv, y,\n",
    "                                                                        test_size=0.5, random_state=42)\n",
    "    X_hrv_train = np.array(X_hrv_train)\n",
    "    y_hrv_train = np.array(y_hrv_train)\n",
    "    X_hrv_test = np.array(X_hrv_test)\n",
    "    y_hrv_test = np.array(y_hrv_test)\n",
    "\n",
    "    X_relax_train, X_relax_test, y_relax_train, y_relax_test = train_test_split(X_relax, y,\n",
    "                                                                                test_size=0.5, random_state=42)\n",
    "    X_relax_train = np.array(X_relax_train)\n",
    "    y_relax_train = np.array(y_relax_train)\n",
    "    X_relax_test = np.array(X_relax_test)\n",
    "    y_relax_test = np.array(y_relax_test)\n",
    "\n",
    "    X_stress_train, X_stress_test, y_stress_train, y_stress_test = train_test_split(X_stress, y,\n",
    "                                                                                    test_size=0.5, random_state=42)\n",
    "    X_stress_train = np.array(X_stress_train)\n",
    "    y_stress_train = np.array(y_stress_train)\n",
    "    X_stress_test = np.array(X_stress_test)\n",
    "    y_stress_test = np.array(y_stress_test)\n",
    "\n",
    "    X_stressSnr_train, X_stressSnr_test, y_stressSnr_train, y_stressSnr_test = train_test_split(X_stressSnr, y,\n",
    "                                                                                                test_size=0.5,\n",
    "                                                                                                random_state=42)\n",
    "    X_stressSnr_train = np.array(X_stressSnr_train)\n",
    "    y_stressSnr_train = np.array(y_stressSnr_train)\n",
    "    X_stressSnr_test = np.array(X_stressSnr_test)\n",
    "    y_stressSnr_test = np.array(y_stressSnr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcff58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646cea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_K = []\n",
    "Acc_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# br classifier\n",
    "classfier_br = KnnDtw(n_neighbors=1, max_warping_window=10)\n",
    "classfier_br.fit(X_br_train, y_br_train)\n",
    "\n",
    "label_br_train, proba, temp_k, temp_acc = classfier_br.predict(X_br_test, y_br_test)\n",
    "best_train_K.append(temp_k)\n",
    "Acc_train.append(temp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3818064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deltaBp classifier\n",
    "classfier_deltaBp = KnnDtw(n_neighbors=1, max_warping_window=10)\n",
    "classfier_deltaBp.fit(X_deltaBp_train, y_deltaBp_train)\n",
    "label_deltaBp_train, proba, temp_k, temp_acc = classfier_deltaBp.predict(X_deltaBp_test, y_deltaBp_train)\n",
    "best_train_K.append(temp_k)\n",
    "Acc_train.append(temp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd9dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hr classifier\n",
    "classfier_hr = KnnDtw(n_neighbors=1, max_warping_window=10)\n",
    "classfier_hr.fit(X_hr_train, y_hr_train)\n",
    "label_hr, proba, temp_k, temp_acc = classfier_hr.predict(X_hr_test, y_hr_train)\n",
    "best_train_K.append(temp_k)\n",
    "Acc_train.append(temp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hrSnr classifier\n",
    "classfier_hrSnr = KnnDtw(n_neighbors=1, max_warping_window=10)\n",
    "classfier_hrSnr.fit(X_hrSnr_train, y_hrSnr_train)\n",
    "label_hrSnr, proba, temp_k, temp_acc = classfier_hrSnr.predict(X_hrSnr_test, y_hrSnr_train)\n",
    "best_train_K.append(temp_k)\n",
    "Acc_train.append(temp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b8524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hrv classifier\n",
    "classfier_hrv = KnnDtw(n_neighbors=1, max_warping_window=10)\n",
    "classfier_hrv.fit(X_hrv_train, y_hrv_train)\n",
    "label_hrv, proba, temp_k, temp_acc = classfier_hrv.predict(X_hrv_test, y_hrv_train)\n",
    "best_train_K.append(temp_k)\n",
    "Acc_train.append(temp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relax classifier\n",
    "classfier_relax = KnnDtw(n_neighbors=1, max_warping_window=10)\n",
    "classfier_relax.fit(X_relax_train, y_relax_train)\n",
    "label_relax, proba, temp_k, temp_acc = classfier_relax.predict(X_relax_test, y_relax_train)\n",
    "best_train_K.append(temp_k)\n",
    "Acc_train.append(temp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stress classifier\n",
    "classfier_stress = KnnDtw(n_neighbors=1, max_warping_window=10)\n",
    "classfier_stress.fit(X_stress_train, y_stress_train)\n",
    "label_stress, proba, temp_k, temp_acc = classfier_stress.predict(X_stress_test, y_stress_train)\n",
    "best_train_K.append(temp_k)\n",
    "Acc_train.append(temp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f616847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stressSnr classifier\n",
    "classfier_stressSnr = KnnDtw(n_neighbors=1, max_warping_window=10)\n",
    "classfier_stressSnr.fit(X_stressSnr_train, y_stressSnr_train)\n",
    "label_stressSnr, proba, temp_k, temp_acc = classfier_stressSnr.predict(X_stressSnr_test, y_stressSnr_train)\n",
    "best_train_K.append(temp_k)\n",
    "Acc_train.append(temp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe72e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best K value of eight classifier:\\n', best_train_K)\n",
    "print('Accuracy:\\n', Acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e938096",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_input = []\n",
    "\n",
    "label_br_train = label_br_train.reshape(-1,1)\n",
    "label_deltaBp_train = label_deltaBp_train.reshape(-1,1)\n",
    "label_hr = label_hr.reshape(-1,1)\n",
    "label_hrSnr = label_hrSnr.reshape(-1,1)\n",
    "label_hrv = label_hrv.reshape(-1,1)\n",
    "label_relax = label_relax.reshape(-1,1)\n",
    "label_stress = label_stress.reshape(-1,1)\n",
    "label_stressSnr = label_stressSnr.reshape(-1,1)\n",
    "\n",
    "NN_input = np.concatenate((label_br_train, label_deltaBp_train, label_hr, label_hrSnr, label_hrv, label_relax, label_stress, label_stressSnr)\n",
    "                          , axis=1)\n",
    "NN_label = y_br_test\n",
    "\n",
    "NN_input_train, NN_input_test, NN_label_train, NN_label_test = train_test_split(NN_input, NN_label,\n",
    "                                                                    test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_classification = KnnDtw(n_neighbors=1, max_warping_window=10)\n",
    "classfier_stressSnr.fit(NN_input_train, NN_label_train)\n",
    "syn_label, proba, syn_k, syn_acc = classfier_stressSnr.predict(NN_input_test, NN_label_test)\n",
    "print(syn_k)\n",
    "print(syn_acc)\n",
    "print(syn_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4faa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(16,16), random_state=1)\n",
    "clf.fit(NN_input_train, NN_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_output = clf.predict(NN_input_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e157e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(NN_input_train, NN_label_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a5dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(NN_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=1).fit(NN_input_train, NN_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4169301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(NN_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f3ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
